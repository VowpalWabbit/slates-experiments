{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from vowpalwabbit import pyvw\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import slates\n",
    "import os\n",
    "def setup_outcomes():\n",
    "    return {('Mac', 'wifi', 'CA'): [], ('Mac', 'wifi', 'US'): [], ('Mac', 'wired', 'CA'): [], ('Mac', 'wired', 'US'): [], ('Windows', 'wifi', 'CA'): [], ('Windows', 'wifi', 'US'): [], ('Windows', 'wired', 'CA'): [], ('Windows', 'wired', 'US'): []}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GROUND_TRUTH_DATASET = \"data/seed7/df_all_8_6_4_0,1.csv\"\n",
    "TEST_DATASETS = {\n",
    "#     \"8_6_4_0,2\" : \"data/seed7/df_all_8_6_4_0,2.csv\",\n",
    "    \"8_6_4_0,1\" : \"data/seed7/df_all_8_6_4_0,1.csv\",\n",
    "#     \"8_6_4_0,01\" : \"data/seed7/df_all_8_6_4_0,01.csv\",\n",
    "#     \"8_6_4_0,001\" : \"data/seed7/df_all_8_6_4_0,001.csv\",\n",
    "#     \"8_6_4_0,0001\" : \"data/seed7/df_all_8_6_4_0,0001.csv\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contexts_to_choose_from = [\n",
    "    ('Mac','wifi','CA'),\n",
    "    ('Mac','wifi','US'),\n",
    "    ('Mac','wired','CA'),\n",
    "    ('Mac','wired','US'),\n",
    "    ('Windows','wifi','CA'),\n",
    "    ('Windows','wifi','US'),\n",
    "    ('Windows','wired','CA'),\n",
    "    ('Windows','wired','US')\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_args = \"--quiet --cb_type mtr --epsilon 0.2 --first_only\"\n",
    "# slates_args = common_args + \" --ccb_explore_adf --coin --slate --interactions UA US SA UAS --l1 1e-6 --clip_p 0.2 --ignore_linear U A S\"\n",
    "slates_args = common_args + \" --slates --coin --interactions UA UUA UUUA\" \n",
    "cb_args = common_args + \" --cb_explore_adf --coin --interactions UA UUA UUUA\"\n",
    "num_iter = 250000\n",
    "\n",
    "# 1 understand if combinatorial works\n",
    "# - It must converge\n",
    "# 2 \n",
    "# - Slates must converge faster\n",
    "# - FInd optimal policy that converged fastest\n",
    "\n",
    "# learning rate 0.001 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_configs = {}\n",
    "for name in TEST_DATASETS:\n",
    "    test_configs[name] = {}\n",
    "    df = pd.read_csv(TEST_DATASETS[name])\n",
    "    test_configs[name][\"data\"] = df\n",
    "    test_configs[name][\"rewards\"] = pd.DataFrame(df.groupby(['platform', 'network', 'country','x','y','z'])['reward'].unique()).reset_index()\n",
    "    test_configs[name][\"x\"] = sorted(df[\"x\"].unique())\n",
    "    test_configs[name][\"y\"] = sorted(df[\"y\"].unique())\n",
    "    test_configs[name][\"z\"] = sorted(df[\"z\"].unique())\n",
    "    test_configs[name][\"x_actions\"] = [\"x=\"+str(a) for a in test_configs[name][\"x\"]]\n",
    "    test_configs[name][\"y_actions\"] = [\"y=\"+str(a) for a in test_configs[name][\"y\"]]\n",
    "    test_configs[name][\"z_actions\"] = [\"z=\"+str(a) for a in test_configs[name][\"z\"]]\n",
    "    \n",
    "    all_string_actions, all_actions = slates.combine_float_actions_categorical(test_configs[name][\"x\"],test_configs[name][\"y\"],test_configs[name][\"z\"])\n",
    "    test_configs[name][\"all_string_actions\"] = all_string_actions\n",
    "    test_configs[name][\"all_actions\"] = all_actions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth_df = pd.read_csv(GROUND_TRUTH_DATASET)\n",
    "ground_truth_rewards_df = pd.DataFrame(ground_truth_df.groupby(['platform', 'network', 'country','x','y','z'])['reward'].unique()).reset_index()\n",
    "\n",
    "min_reward = {}\n",
    "min_actions = {}\n",
    "\n",
    "plt.figure(figsize=(20, 10))\n",
    "\n",
    "grps_context = ground_truth_df.groupby(['platform', 'network', 'country'])\n",
    "for i, context in enumerate(grps_context.groups.keys()):\n",
    "    df_temp = grps_context.get_group(context)\n",
    "    if context not in min_reward.keys():\n",
    "        min_reward[context] = {}\n",
    "    grps_action = df_temp.groupby(['x', 'y', 'z'])\n",
    "    for action in grps_action.groups.keys():\n",
    "        df_temp2 = grps_action.get_group(action)\n",
    "        min_reward[context][action] = np.mean(df_temp2['reward'])\n",
    "        \n",
    "    min_reward_action = min(min_reward[context], key=min_reward[context].get)\n",
    "    min_actions[context] = min_reward_action\n",
    "    plt.boxplot(grps_action.get_group(min_reward_action)[\"reward\"], positions=[i], labels=[\"{}\".format(context)], showmeans=True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,40))\n",
    "data = min_reward[('Windows', 'wired', 'US')]\n",
    "x = data.keys()\n",
    "average_values = data.values()\n",
    "print(\"Number of actions\", len(average_values))\n",
    "x_pos = [i for i, _ in enumerate(x)]\n",
    "plt.yticks(x_pos, x)\n",
    "\n",
    "plt.barh(x_pos, average_values)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# min_actions[('Mac', 'wifi', 'CA')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimal_policy_sample(context, action):\n",
    "    row_index = ground_truth_rewards_df.index[(ground_truth_rewards_df['platform'] == context[0])\n",
    "                                           & (ground_truth_rewards_df['network'] == context[1])\n",
    "                                           & (ground_truth_rewards_df['country'] == context[2])\n",
    "                                           & (ground_truth_rewards_df['x'] == action[0])\n",
    "                                           & (ground_truth_rewards_df['y'] == action[1])\n",
    "                                           & (ground_truth_rewards_df['z'] == action[2])\n",
    "                                          ]\n",
    "    possible_rewards = ground_truth_rewards_df.iloc[row_index[0]][\"reward\"]\n",
    "    return np.random.choice(possible_rewards)\n",
    "\n",
    "def optimal_policy_median(context, action):\n",
    "    row_index = ground_truth_rewards_df.index[(ground_truth_rewards_df['platform'] == context[0])\n",
    "                                           & (ground_truth_rewards_df['network'] == context[1])\n",
    "                                           & (ground_truth_rewards_df['country'] == context[2])\n",
    "                                           & (ground_truth_rewards_df['x'] == action[0])\n",
    "                                           & (ground_truth_rewards_df['y'] == action[1])\n",
    "                                           & (ground_truth_rewards_df['z'] == action[2])\n",
    "                                          ]\n",
    "    possible_rewards = ground_truth_rewards_df.iloc[row_index[0]][\"reward\"]\n",
    "    return np.median(possible_rewards)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Slates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "trajectory_strings = []\n",
    "for name in test_configs:\n",
    "    test_configs[name][\"outcomes\"] = setup_outcomes()\n",
    "    test_configs[name][\"x_outcomes\"] = setup_outcomes()\n",
    "    test_configs[name][\"y_outcomes\"] = setup_outcomes()\n",
    "    test_configs[name][\"z_outcomes\"] = setup_outcomes()\n",
    "    \n",
    "    model = pyvw.vw(slates_args)\n",
    "\n",
    "    df = test_configs[name][\"data\"]\n",
    "    rewards = test_configs[name][\"rewards\"]\n",
    "\n",
    "    for i in range(num_iter):\n",
    "        if i % 1000 == 0:\n",
    "            print(i)\n",
    "        platform,network,country = contexts_to_choose_from[np.random.choice(len(contexts_to_choose_from))]\n",
    "        \n",
    "        shared_context = \"platform={} region={} connection={}\".format(platform, country, network)\n",
    "        examples = slates.create_native_slates_example(model, shared_context, [test_configs[name][\"x_actions\"], test_configs[name][\"y_actions\"], test_configs[name][\"z_actions\"]])\n",
    "        pred = model.predict(examples, prediction_type=pyvw.pylibvw.vw.pDECISION_SCORES)\n",
    "        model.finish_example(examples)\n",
    "        \n",
    "#         print(pred)\n",
    "        \n",
    "        # Choose the slot to samlpe\n",
    "        chosen_slot = np.random.choice(len(pred))\n",
    "        slot_to_sample = pred[chosen_slot]\n",
    "        # Sample an index from this slot\n",
    "        index = slates.sample_index(slot_to_sample)\n",
    "        # Swap sampled action if it was not the 0th item.\n",
    "        if index != 0:\n",
    "            slot_to_sample[0], slot_to_sample[index] = slot_to_sample[index], slot_to_sample[0]\n",
    "        # Assign the potentially modified slot back into the prediction\n",
    "        pred[chosen_slot] = slot_to_sample\n",
    "        \n",
    "        exploit_a = 0\n",
    "        for pred_a in pred:\n",
    "            all_probs = [x[1] for x in pred_a]\n",
    "            if pred_a[0][0] == max(pred_a,key=lambda x:x[1])[0] and not(all_probs[1:] == all_probs[:-1]):\n",
    "                exploit_a +=1\n",
    "\n",
    "        chosen_x = test_configs[name][\"x\"][pred[0][0][0]]\n",
    "        chosen_y = test_configs[name][\"y\"][pred[1][0][0]]\n",
    "        chosen_z = test_configs[name][\"z\"][pred[2][0][0]]\n",
    "        \n",
    "        # \"['Windows', 'wired', 'CA']\",\"(3.79, 0.11, 1.05)\",8\n",
    "        trajectory_strings.append(f\"\\\"('{platform}', '{network}', '{country}')\\\",\\\"({chosen_x},{chosen_y},{chosen_z})\\\",1\")\n",
    "               \n",
    "        row_index = rewards.index[(rewards['platform'] == platform)\n",
    "                                       & (rewards['network'] == network)\n",
    "                                       & (rewards['country'] == country)\n",
    "                                       & (rewards['x'] == chosen_x)\n",
    "                                       & (rewards['y'] == chosen_y)\n",
    "                                       & (rewards['z'] == chosen_z)\n",
    "                                      ]\n",
    "        # Choose a reward from the set that matched this example\n",
    "        possible_rewards = rewards.iloc[row_index[0]][\"reward\"]\n",
    "        cost = np.random.choice(possible_rewards)\n",
    "\n",
    "        x_index = test_configs[name][\"x_actions\"].index(\"x=\"+str(chosen_x))\n",
    "        y_index = test_configs[name][\"y_actions\"].index(\"y=\"+str(chosen_y))\n",
    "        z_index = test_configs[name][\"z_actions\"].index(\"z=\"+str(chosen_z))\n",
    "        x_outcome = (x_index, cost, pred[0][0][1])\n",
    "        y_outcome = (y_index, cost, pred[1][0][1])\n",
    "        z_outcome = (z_index, cost, pred[2][0][1])\n",
    "        \n",
    "        # Only save the outcome for plotting if it was exploit\n",
    "#         print(exploit_a)\n",
    "        if exploit_a == 3:\n",
    "            test_configs[name][\"outcomes\"][(platform,network,country)].append(cost)\n",
    "            test_configs[name][\"x_outcomes\"][(platform,network,country)].append(test_configs[name][\"x\"][x_index])\n",
    "            test_configs[name][\"y_outcomes\"][(platform,network,country)].append(test_configs[name][\"y\"][y_index])\n",
    "            test_configs[name][\"z_outcomes\"][(platform,network,country)].append(test_configs[name][\"z\"][z_index])\n",
    "\n",
    "        examples = slates.create_native_slates_example(model, shared_context, [test_configs[name][\"x_actions\"], test_configs[name][\"y_actions\"], test_configs[name][\"z_actions\"]], [x_outcome,y_outcome,z_outcome], debug=False)\n",
    "        model.learn(examples)\n",
    "        model.finish_example(examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('slate_trajectory2.csv', 'w') as f:\n",
    "    for line in trajectory_strings:\n",
    "        f.write(line + os.linesep)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combinatorial CB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name in test_configs:\n",
    "    test_configs[name][\"cb_outcomes\"] = setup_outcomes()\n",
    "    test_configs[name][\"cb_x_outcomes\"] = setup_outcomes()\n",
    "    test_configs[name][\"cb_y_outcomes\"] = setup_outcomes()\n",
    "    test_configs[name][\"cb_z_outcomes\"] = setup_outcomes()\n",
    "    \n",
    "    cb_model = pyvw.vw(cb_args)\n",
    "\n",
    "\n",
    "    df = test_configs[name][\"data\"]\n",
    "    rewards = test_configs[name][\"rewards\"]\n",
    "    for i in range(num_iter):\n",
    "        if i % 1000 == 0:\n",
    "            print(i)\n",
    "        platform,network,country = contexts_to_choose_from[np.random.choice(len(contexts_to_choose_from))]\n",
    "\n",
    "        shared_context = \"platform={} region={} connection={}\".format(platform, country, network)\n",
    "        examples = slates.create_cb_example(cb_model, shared_context, test_configs[name][\"all_string_actions\"])\n",
    "        pred = cb_model.predict(examples, prediction_type=pyvw.pylibvw.vw.pACTION_SCORES)\n",
    "        cb_model.finish_example(examples)\n",
    "        \n",
    "       # print(pred)\n",
    "\n",
    "        # Sample\n",
    "        pred_sum = sum(pred)\n",
    "        pred = [float(i)/pred_sum for i in pred]\n",
    "        chosen_action_index = np.random.choice(len(pred), p=pred)\n",
    "        chosen_action = test_configs[name][\"all_actions\"][chosen_action_index]\n",
    "        chosen_pred = pred[chosen_action_index]\n",
    "\n",
    "        row_index = rewards.index[(rewards['platform'] == platform)\n",
    "                                       & (rewards['network'] == network)\n",
    "                                       & (rewards['country'] == country)\n",
    "                                       & (rewards['x'] == chosen_action[0])\n",
    "                                       & (rewards['y'] == chosen_action[1])\n",
    "                                       & (rewards['z'] == chosen_action[2])\n",
    "                                      ]\n",
    "\n",
    "        # Choose a reward from the set that matched this example\n",
    "        possible_rewards = rewards.iloc[row_index[0]][\"reward\"]\n",
    "        cost = np.random.choice(possible_rewards)\n",
    "        \n",
    "        # Only save the outcome for plotting if it was exploit\n",
    "        if(chosen_pred == max(pred) and not(pred[1:] == pred[:-1])):\n",
    "            test_configs[name][\"cb_outcomes\"][(platform,network,country)].append(cost)\n",
    "            test_configs[name][\"cb_x_outcomes\"][(platform,network,country)].append(chosen_action[0])\n",
    "            test_configs[name][\"cb_y_outcomes\"][(platform,network,country)].append(chosen_action[1])\n",
    "            test_configs[name][\"cb_z_outcomes\"][(platform,network,country)].append(chosen_action[2])    \n",
    "\n",
    "        examples = slates.create_cb_example(cb_model, shared_context, test_configs[name][\"all_string_actions\"], outcome=(chosen_action_index, cost, chosen_pred))\n",
    "        cb_model.learn(examples)\n",
    "        cb_model.finish_example(examples)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "contexts = sorted(list(test_configs[next(iter(test_configs))][\"outcomes\"].keys()))\n",
    "\n",
    "prop_cycle = plt.rcParams['axes.prop_cycle']\n",
    "colors = prop_cycle.by_key()['color']\n",
    "\n",
    "for context in contexts:\n",
    "    plt.figure(figsize=(20, 8))\n",
    "#     slates_trimmed = test_configs[name][\"outcomes\"][context] # All of them\n",
    "#     cb_trimmed = test_configs[name][\"cb_outcomes\"][context]# All of them\n",
    "#     number_of_samples = max(len(slates_trimmed), len(cb_trimmed))\n",
    "    number_of_samples = int(num_iter / 16)\n",
    "    for i, name in enumerate(test_configs):\n",
    "        samples = test_configs[name][\"outcomes\"][context]\n",
    "        window_size = int(len(samples) / 10)\n",
    "        plt.plot(pd.Series(np.log(samples)).rolling(window_size, min_periods=0).mean(), color=colors[i], label=\"{} slate\".format(name))\n",
    "#         plt.plot(pd.Series(cb_trimmed).rolling(window_size, min_periods=0).mean(), color=cb_colors[i], label=\"{} combinatorial\".format(name))\n",
    "    \n",
    "    plt.ylabel(\"Cost\")\n",
    "    # Plot optimal policy by sampling optimal policy number_of_samples times\n",
    "    optimal_policy_results = [optimal_policy_sample(context, min_actions[context]) for i in range(number_of_samples)]\n",
    "    plt.plot(pd.Series(np.log(optimal_policy_results)).rolling(int(number_of_samples/10), min_periods=0).mean(), color='b', linestyle=':', label=\"best avg\")\n",
    "#     plt.ylim(0.04,0.1)\n",
    "    plt.axhline(y=np.log(0.05), color='g', linestyle=':')\n",
    "    plt.title(\"{}\".format(context))\n",
    "    plt.legend(loc=\"upper right\")\n",
    "    plt.show()\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "contexts = sorted(list(test_configs[next(iter(test_configs))][\"outcomes\"].keys()))\n",
    "\n",
    "slate_colors = ['#004c97','#000097','#009797']\n",
    "cb_colors = ['#ad0603', '#ad5b03', '#ad0355']\n",
    "\n",
    "for context in contexts:\n",
    "    for i, name in enumerate(test_configs):\n",
    "        data = test_configs[name][\"x_outcomes\"][context]\n",
    "        actions = sorted(np.unique(data))\n",
    "        x_action_counts = [sum(value == action for value in data) for action in actions]\n",
    "        plt.bar(np.arange(len(actions)), x_action_counts)\n",
    "        plt.xticks(np.arange(len(actions)), actions)\n",
    "        plt.title(\"{} - X\".format(context))\n",
    "        plt.show()\n",
    "        \n",
    "        data = test_configs[name][\"y_outcomes\"][context]\n",
    "        actions = sorted(np.unique(data))\n",
    "        x_action_counts = [sum(value == action for value in data) for action in actions]\n",
    "        plt.bar(np.arange(len(actions)), x_action_counts, color='g')\n",
    "        plt.xticks(np.arange(len(actions)), actions)\n",
    "        plt.title(\"{} - Y\".format(context))\n",
    "        plt.show()\n",
    "        \n",
    "        data = test_configs[name][\"z_outcomes\"][context]\n",
    "        actions = sorted(np.unique(data))\n",
    "        x_action_counts = [sum(value == action for value in data) for action in actions]\n",
    "        plt.bar(np.arange(len(actions)), x_action_counts, color='y')\n",
    "        plt.xticks(np.arange(len(actions)), actions)\n",
    "        plt.title(\"{} - Z\".format(context))\n",
    "        plt.show()\n",
    "               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "contexts = sorted(list(test_configs[next(iter(test_configs))][\"outcomes\"].keys()))\n",
    "\n",
    "prop_cycle = plt.rcParams['axes.prop_cycle']\n",
    "colors = prop_cycle.by_key()['color']\n",
    "\n",
    "for context in contexts:\n",
    "    plt.figure(figsize=(20, 8))\n",
    "#     slates_trimmed = test_configs[name][\"outcomes\"][context] # All of them\n",
    "#     cb_trimmed = test_configs[name][\"cb_outcomes\"][context]# All of them\n",
    "#     number_of_samples = max(len(slates_trimmed), len(cb_trimmed))\n",
    "    number_of_samples = int(num_iter / 16)\n",
    "    for i, name in enumerate(test_configs):\n",
    "        samples = test_configs[name][\"outcomes\"][context]\n",
    "        window_size = int(len(samples) / 10)\n",
    "        plt.plot(pd.Series(samples).rolling(window_size, min_periods=0).mean(), color=colors[i], label=\"{} slate\".format(name))\n",
    "#         plt.plot(pd.Series(cb_trimmed).rolling(window_size, min_periods=0).mean(), color=cb_colors[i], label=\"{} combinatorial\".format(name))\n",
    "    \n",
    "    plt.ylabel(\"Cost\")\n",
    "    # Plot optimal policy by sampling optimal policy number_of_samples times\n",
    "    optimal_policy_results = [optimal_policy_sample(context, min_actions[context]) for i in range(number_of_samples)]\n",
    "    plt.plot(pd.Series(optimal_policy_results).rolling(120, min_periods=0).mean(), color='b', linestyle=':', label=\"best avg\")\n",
    "#     plt.ylim(0.04,0.1)\n",
    "    plt.axhline(y=0.05, color='g', linestyle=':')\n",
    "    plt.title(\"{}\".format(context))\n",
    "    plt.legend(loc=\"upper right\")\n",
    "    plt.show()\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}