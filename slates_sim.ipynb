{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from vowpalwabbit import pyvw\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import slates\n",
    "\n",
    "def setup_outcomes():\n",
    "    return {('Mac', 'wifi', 'CA'): [], ('Mac', 'wifi', 'US'): [], ('Mac', 'wired', 'CA'): [], ('Mac', 'wired', 'US'): [], ('Windows', 'wifi', 'CA'): [], ('Windows', 'wifi', 'US'): [], ('Windows', 'wired', 'CA'): [], ('Windows', 'wired', 'US'): []}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GROUND_TRUTH_DATASET = \"data/df_all_4_3_2_100runs.csv\"\n",
    "TEST_DATASETS = {\n",
    "#     \"20_15_10\" : \"data/gen/df_all_20_15_10_5runs.csv\",\n",
    "#     \"20_15_10\" : \"data/df_all_20_15_10_5runs.csv\"\n",
    "    \"4_3_2\" : \"data/df_all_4_3_2_50runs.csv\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_configs = {}\n",
    "for name in TEST_DATASETS:\n",
    "    test_configs[name] = {}\n",
    "    df = pd.read_csv(TEST_DATASETS[name])\n",
    "    test_configs[name][\"data\"] = df\n",
    "    test_configs[name][\"rewards\"] = pd.DataFrame(df.groupby(['platform', 'network', 'country','x','y','z'])['reward'].unique()).reset_index()\n",
    "    test_configs[name][\"x\"] = sorted(df[\"x\"].unique())\n",
    "    test_configs[name][\"y\"] = sorted(df[\"y\"].unique())\n",
    "    test_configs[name][\"z\"] = sorted(df[\"z\"].unique())\n",
    "    test_configs[name][\"x_actions\"] = [\"x=\"+str(a) for a in test_configs[name][\"x\"]]\n",
    "    test_configs[name][\"y_actions\"] = [\"y=\"+str(a) for a in test_configs[name][\"y\"]]\n",
    "    test_configs[name][\"z_actions\"] = [\"z=\"+str(a) for a in test_configs[name][\"z\"]]\n",
    "    \n",
    "    all_string_actions, all_actions = slates.combine_float_actions(test_configs[name][\"x\"],test_configs[name][\"y\"],test_configs[name][\"z\"])\n",
    "    test_configs[name][\"all_string_actions\"] = all_string_actions\n",
    "    test_configs[name][\"all_actions\"] = all_actions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth_df = pd.read_csv(GROUND_TRUTH_DATASET)\n",
    "ground_truth_rewards_df = pd.DataFrame(ground_truth_df.groupby(['platform', 'network', 'country','x','y','z'])['reward'].unique()).reset_index()\n",
    "\n",
    "min_reward = {}\n",
    "min_actions = {}\n",
    "\n",
    "plt.figure(figsize=(20, 10))\n",
    "\n",
    "grps_context = ground_truth_df.groupby(['platform', 'network', 'country'])\n",
    "for i, context in enumerate(grps_context.groups.keys()):\n",
    "    df_temp = grps_context.get_group(context)\n",
    "    if context not in min_reward.keys():\n",
    "        min_reward[context] = {}\n",
    "    grps_action = df_temp.groupby(['x', 'y', 'z'])\n",
    "    for action in grps_action.groups.keys():\n",
    "        df_temp2 = grps_action.get_group(action)\n",
    "        min_reward[context][action] = np.mean(df_temp2['reward'])\n",
    "        \n",
    "    min_reward_action = min(min_reward[context], key=min_reward[context].get)\n",
    "    min_actions[context] = min_reward_action\n",
    "    plt.boxplot(grps_action.get_group(min_reward_action)[\"reward\"], positions=[i], labels=[\"{}\".format(context)], showmeans=True)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimal_policy_sample(context, action):\n",
    "    row_index = ground_truth_rewards_df.index[(ground_truth_rewards_df['platform'] == context[0])\n",
    "                                           & (ground_truth_rewards_df['network'] == context[1])\n",
    "                                           & (ground_truth_rewards_df['country'] == context[2])\n",
    "                                           & (ground_truth_rewards_df['x'] == action[0])\n",
    "                                           & (ground_truth_rewards_df['y'] == action[1])\n",
    "                                           & (ground_truth_rewards_df['z'] == action[2])\n",
    "                                          ]\n",
    "    possible_rewards = ground_truth_rewards_df.iloc[row_index[0]][\"reward\"]\n",
    "    return np.random.choice(possible_rewards)\n",
    "\n",
    "def optimal_policy_median(context, action):\n",
    "    row_index = ground_truth_rewards_df.index[(ground_truth_rewards_df['platform'] == context[0])\n",
    "                                           & (ground_truth_rewards_df['network'] == context[1])\n",
    "                                           & (ground_truth_rewards_df['country'] == context[2])\n",
    "                                           & (ground_truth_rewards_df['x'] == action[0])\n",
    "                                           & (ground_truth_rewards_df['y'] == action[1])\n",
    "                                           & (ground_truth_rewards_df['z'] == action[2])\n",
    "                                          ]\n",
    "    possible_rewards = ground_truth_rewards_df.iloc[row_index[0]][\"reward\"]\n",
    "    return np.median(possible_rewards)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Slates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name in test_configs:\n",
    "    test_configs[name][\"outcomes\"] = setup_outcomes()\n",
    "    test_configs[name][\"x_outcomes\"] = setup_outcomes()\n",
    "    test_configs[name][\"y_outcomes\"] = setup_outcomes()\n",
    "    test_configs[name][\"z_outcomes\"] = setup_outcomes()\n",
    "    \n",
    "    model = pyvw.vw(\"--ccb_explore_adf --cb_type ips --power_t 0 -l 0.005 --slate --quiet --epsilon 0.2 -q :: --interactions UUU AAA UUA AAU UUUA UUUAA UUUAAA\")\n",
    "\n",
    "    df = test_configs[name][\"data\"]\n",
    "    rewards = test_configs[name][\"rewards\"]\n",
    "\n",
    "    for _ in range(10000):\n",
    "        choice = np.random.choice(len(df))\n",
    "        current_row = df.iloc[choice]\n",
    "        platform = current_row[\"platform\"]\n",
    "        country = current_row[\"country\"]\n",
    "        network = current_row[\"network\"]\n",
    "\n",
    "        shared_context = \"platform={} region={} connection={}\".format(platform, country, network)\n",
    "        examples = slates.create_slates_example(model, shared_context, [test_configs[name][\"x_actions\"], test_configs[name][\"y_actions\"], test_configs[name][\"z_actions\"]])\n",
    "        pred = slates.slate_pred_conv(model.predict(examples, prediction_type=pyvw.pylibvw.vw.pDECISION_SCORES))\n",
    "        model.finish_example(examples)\n",
    "        \n",
    "        # Choose the slot to samlpe\n",
    "        chosen_slot = np.random.choice(len(pred))\n",
    "        slot_to_sample = pred[chosen_slot]\n",
    "        # Sample an index from this slot\n",
    "        index = slates.sample_index(slot_to_sample)\n",
    "        # Swap sampled action if it was not the 0th item.\n",
    "        if index != 0:\n",
    "            slot_to_sample[0], slot_to_sample[index] = slot_to_sample[index], slot_to_sample[0]\n",
    "        # Assign the potentially modified slot back into the prediction\n",
    "        pred[chosen_slot] = slot_to_sample\n",
    "        \n",
    "        exploit_a = 0\n",
    "        for pred_a in pred:\n",
    "            all_probs = [x[1] for x in pred_a]\n",
    "            if pred_a[0][0] == max(pred_a,key=lambda x:x[1])[0] and not(all_probs[1:] == all_probs[:-1]):\n",
    "                exploit_a +=1\n",
    "\n",
    "        chosen_x = test_configs[name][\"x\"][pred[0][0][0]]\n",
    "        chosen_y = test_configs[name][\"y\"][pred[1][0][0]]\n",
    "        chosen_z = test_configs[name][\"z\"][pred[2][0][0]]\n",
    "               \n",
    "        row_index = rewards.index[(rewards['platform'] == platform)\n",
    "                                       & (rewards['network'] == network)\n",
    "                                       & (rewards['country'] == country)\n",
    "                                       & (rewards['x'] == chosen_x)\n",
    "                                       & (rewards['y'] == chosen_y)\n",
    "                                       & (rewards['z'] == chosen_z)\n",
    "                                      ]\n",
    "        # Choose a reward from the set that matched this example\n",
    "        possible_rewards = rewards.iloc[row_index[0]][\"reward\"]\n",
    "        cost = np.random.choice(possible_rewards)\n",
    "        test_configs[name][\"outcomes\"][(platform,network,country)].append(cost)\n",
    "\n",
    "        x_index = test_configs[name][\"x_actions\"].index(\"x=\"+str(chosen_x))\n",
    "        y_index = test_configs[name][\"y_actions\"].index(\"y=\"+str(chosen_y))\n",
    "        z_index = test_configs[name][\"z_actions\"].index(\"z=\"+str(chosen_z))\n",
    "        x_outcome = (x_index, cost, pred[0][0][1])\n",
    "        y_outcome = (y_index, cost, pred[1][0][1])\n",
    "        z_outcome = (z_index, cost, pred[2][0][1])\n",
    "        \n",
    "        # Only save the outcome for plotting if it was exploit\n",
    "        if exploit_a == 3:\n",
    "            test_configs[name][\"x_outcomes\"][(platform,network,country)].append(test_configs[name][\"x\"][x_index])\n",
    "            test_configs[name][\"y_outcomes\"][(platform,network,country)].append(test_configs[name][\"y\"][y_index])\n",
    "            test_configs[name][\"z_outcomes\"][(platform,network,country)].append(test_configs[name][\"z\"][z_index])\n",
    "\n",
    "        examples = slates.create_slates_example(model, shared_context, [test_configs[name][\"x_actions\"], test_configs[name][\"y_actions\"], test_configs[name][\"z_actions\"]], [x_outcome,y_outcome,z_outcome])\n",
    "        model.learn(examples)\n",
    "        model.finish_example(examples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combinatorial CB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name in test_configs:\n",
    "    test_configs[name][\"cb_outcomes\"] = setup_outcomes()\n",
    "    test_configs[name][\"cb_x_outcomes\"] = setup_outcomes()\n",
    "    test_configs[name][\"cb_y_outcomes\"] = setup_outcomes()\n",
    "    test_configs[name][\"cb_z_outcomes\"] = setup_outcomes()\n",
    "    \n",
    "    cb_model = pyvw.vw(\"--cb_explore_adf --cb_type ips --power_t 0 -l 0.005 --quiet --epsilon 0.2 -q :: --interactions UUU AAA UUA AAU UUUA UUUAA UUUAAA\")\n",
    "\n",
    "\n",
    "    df = test_configs[name][\"data\"]\n",
    "    rewards = test_configs[name][\"rewards\"]\n",
    "    for _ in range(10000):\n",
    "        choice = np.random.choice(len(df))\n",
    "        current_row = df.iloc[choice]\n",
    "        platform = current_row[\"platform\"]\n",
    "        country = current_row[\"country\"]\n",
    "        network = current_row[\"network\"]\n",
    "\n",
    "        shared_context = \"platform={} region={} connection={}\".format(platform, country, network)\n",
    "        examples = slates.create_cb_example(cb_model, shared_context, test_configs[name][\"all_string_actions\"])\n",
    "        pred = cb_model.predict(examples, prediction_type=pyvw.pylibvw.vw.pACTION_SCORES)\n",
    "        cb_model.finish_example(examples)\n",
    "\n",
    "        # Sample\n",
    "        pred_sum = sum(pred)\n",
    "        pred = [float(i)/pred_sum for i in pred]\n",
    "        chosen_action_index = np.random.choice(len(pred), p=pred)\n",
    "        chosen_action = test_configs[name][\"all_actions\"][chosen_action_index]\n",
    "        chosen_pred = pred[chosen_action_index]\n",
    "\n",
    "        row_index = rewards.index[(rewards['platform'] == platform)\n",
    "                                       & (rewards['network'] == network)\n",
    "                                       & (rewards['country'] == country)\n",
    "                                       & (rewards['x'] == chosen_action[0])\n",
    "                                       & (rewards['y'] == chosen_action[1])\n",
    "                                       & (rewards['z'] == chosen_action[2])\n",
    "                                      ]\n",
    "\n",
    "        # Choose a reward from the set that matched this example\n",
    "        possible_rewards = rewards.iloc[row_index[0]][\"reward\"]\n",
    "        cost = np.random.choice(possible_rewards)\n",
    "        test_configs[name][\"cb_outcomes\"][(platform,network,country)].append(cost)\n",
    "        \n",
    "        # Only save the outcome for plotting if it was exploit\n",
    "        if(chosen_pred > 0.5):\n",
    "            test_configs[name][\"cb_x_outcomes\"][(platform,network,country)].append(chosen_action[0])\n",
    "            test_configs[name][\"cb_y_outcomes\"][(platform,network,country)].append(chosen_action[1])\n",
    "            test_configs[name][\"cb_z_outcomes\"][(platform,network,country)].append(chosen_action[2])    \n",
    "\n",
    "        examples = slates.create_cb_example(cb_model, shared_context, test_configs[name][\"all_string_actions\"], outcome=(chosen_action_index, cost, chosen_pred))\n",
    "        cb_model.learn(examples)\n",
    "        cb_model.finish_example(examples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "contexts = sorted(list(test_configs[next(iter(test_configs))][\"outcomes\"].keys()))\n",
    "\n",
    "slate_colors = ['#004c97','#000097','#009797']\n",
    "cb_colors = ['#ad0603', '#ad5b03', '#ad0355']\n",
    "\n",
    "for context in contexts:\n",
    "    plt.figure(figsize=(20, 8))\n",
    "    number_of_samples = max(len(test_configs[name][\"outcomes\"][context]), len(test_configs[name][\"cb_outcomes\"][context]))\n",
    "    for i, name in enumerate(test_configs):\n",
    "        plt.plot(pd.Series(test_configs[name][\"outcomes\"][context]).rolling(100, min_periods=0).mean(), color=slate_colors[i], label=\"{} slate\".format(name))\n",
    "        plt.plot(pd.Series(test_configs[name][\"cb_outcomes\"][context]).rolling(100, min_periods=0).mean(), color=cb_colors[i], label=\"{} combinatorial\".format(name))\n",
    "    \n",
    "    plt.ylabel(\"Cost\")\n",
    "    # Plot optimal policy by sampling optimal policy number_of_samples times\n",
    "    optimal_policy_results = [optimal_policy_sample(context, min_actions[context]) for i in range(number_of_samples)]\n",
    "    plt.plot(pd.Series(optimal_policy_results).rolling(120, min_periods=0).mean(), color='b', linestyle=':', label=\"best avg\")\n",
    "\n",
    "    plt.title(\"{}\".format(context))\n",
    "    plt.legend(loc=\"upper right\")\n",
    "    plt.show()\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "contexts = sorted(list(test_configs[next(iter(test_configs))][\"outcomes\"].keys()))\n",
    "\n",
    "slate_colors = ['#004c97','#000097','#009797']\n",
    "cb_colors = ['#ad0603', '#ad5b03', '#ad0355']\n",
    "\n",
    "for context in contexts:\n",
    "    for i, name in enumerate(test_configs):\n",
    "        data = test_configs[name][\"x_outcomes\"][context]\n",
    "        actions = sorted(np.unique(data))\n",
    "        x_action_counts = [sum(value == action for value in data) for action in actions]\n",
    "        plt.bar(np.arange(len(actions)), x_action_counts)\n",
    "        plt.xticks(np.arange(len(actions)), actions)\n",
    "        plt.title(\"{} - X\".format(context))\n",
    "        plt.show()\n",
    "        \n",
    "        data = test_configs[name][\"y_outcomes\"][context]\n",
    "        actions = sorted(np.unique(data))\n",
    "        x_action_counts = [sum(value == action for value in data) for action in actions]\n",
    "        plt.bar(np.arange(len(actions)), x_action_counts, color='g')\n",
    "        plt.xticks(np.arange(len(actions)), actions)\n",
    "        plt.title(\"{} - Y\".format(context))\n",
    "        plt.show()\n",
    "        \n",
    "        data = test_configs[name][\"z_outcomes\"][context]\n",
    "        actions = sorted(np.unique(data))\n",
    "        x_action_counts = [sum(value == action for value in data) for action in actions]\n",
    "        plt.bar(np.arange(len(actions)), x_action_counts, color='y')\n",
    "        plt.xticks(np.arange(len(actions)), actions)\n",
    "        plt.title(\"{} - Z\".format(context))\n",
    "        plt.show()\n",
    "               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
