{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Synthetic Continuous Multi-Parameter Scenario\n",
    "\n",
    "We use this notebook to generate simulated datasets for the multi-dimensional parameter tuning solutions in the continuous action space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import itertools\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "from IPython.display import Markdown, display\n",
    "from multi_d_simulator import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Parameters\n",
    "\n",
    "In this section, we define how the data will look like. Some key aspects that you can control:\n",
    "* Contexts\n",
    "* Number of actions and the corresponding ranges\n",
    "* Reward range\n",
    "* Noise level\n",
    "* Discretization policies\n",
    "* Number of samples per context*action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simulator_args = dict(\n",
    "    \n",
    "    # Working directory\n",
    "    folder_path = r'E:\\data\\20200214_vector_plearning_msrnyc\\data1',\n",
    "    \n",
    "    # Context\n",
    "    contexts = {\n",
    "        'platform': ['Mac', 'Windows'], \n",
    "        'network': ['wifi', 'wired'], \n",
    "        'country': ['US', 'CA']\n",
    "    },\n",
    "    \n",
    "    # Action\n",
    "    actions = {\n",
    "        'x': {'mean': 2, 'min': 0, 'max': 4, 'std_range': [0.1, 2.0]},\n",
    "        'y': {'mean': 1, 'min': 0, 'max': 3, 'std_range': [0.1, 2.0]}, \n",
    "        'z': {'mean': 3, 'min': 0, 'max': 5, 'std_range': [0.1, 2.0]}\n",
    "    },\n",
    "    discretization_fine_grain = 100,\n",
    "    discretization_policy = {'x': 8, 'y': 6, 'z': 4},\n",
    "    share_discretized_grid = True,\n",
    "    \n",
    "    # Reward\n",
    "    reward_range = [0.05, 0.35],\n",
    "    reward_minimization = True,\n",
    "    interaction_level = 3,\n",
    "    coefficient_range = [0.1, 2],\n",
    "    \n",
    "    # Shift from the base surface (multipliers)\n",
    "    coefficient_scale_range = [0.8, 1.2], \n",
    "    dist_mean_change_range = [0.7, 1.3],\n",
    "    dist_std_change_range = [0.7, 1.3],\n",
    "    \n",
    "    # Sample size and Noise \n",
    "    # (known_n_per_config: Int or False. If False, the sample size will estimated according to the required confidence level)\n",
    "    known_n_per_config = 10,\n",
    "    ci_mean = 0,\n",
    "    ci_std = 0.01,\n",
    "    ci_width = 0.005,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a simulator\n",
    "sim = MultiDSimulator(**simulator_args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Generate a Base Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a base distribution\n",
    "display(Markdown('### >>> Base Distribution'))\n",
    "config_base = sim.gen_param_reward(plot=True)\n",
    "\n",
    "# Complete Reward Formula\n",
    "sim.discretize(config_base)\n",
    "display(Markdown('* {0}'.format(config_base['configs']['reward_equation'])))\n",
    "\n",
    "# Generate groundtruth data\n",
    "num_values, _, _ = sim.gen_data(config_base, 1, add_error=False, plot_2d=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Adjust Distributions and Coefficients by Context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialization\n",
    "config_context = {}\n",
    "config_output = {}\n",
    "discretized_context = {}\n",
    "df_summary = pd.DataFrame()\n",
    "df_all = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Adjust\n",
    "sim.random_changes()\n",
    "for j, c in enumerate(sim.unique_contexts):\n",
    "    \n",
    "    # Context Information\n",
    "    c_name = '_'.join(c)\n",
    "    display(Markdown('### >>> [{0}/{1}] Generating data for context {2}'.format(j+1, len(sim.unique_contexts), c_name)))\n",
    "    display(Markdown('####   Distribution'))\n",
    "\n",
    "    # Adjust Distribution\n",
    "    sim.adjust_distributuion(config_context, config_base, c, plot=True)\n",
    "        \n",
    "    # Adjust Coefficients\n",
    "    c_coeff = sim.adjust_coefficients(c)\n",
    "    \n",
    "    # Ground Truth\n",
    "    display(Markdown('####   Ground Truth'))\n",
    "    sim.discretize(config_context[c_name], coefficients=c_coeff)\n",
    "    config_context[c_name]['configs']['coefficients'] = c_coeff\n",
    "    display(Markdown('* {0}'.format(config_context[c_name]['configs']['reward_equation'])))\n",
    "\n",
    "    # Generate ground truth data\n",
    "    num_values, reward_raw_min, reward_raw_max = sim.gen_data(config_context[c_name], 1, coefficients=c_coeff, add_error=False, plot_2d=True)\n",
    "    \n",
    "    # Generate output data by the specified discretization policies\n",
    "    display(Markdown('####   Discretized Sapce'))  \n",
    "    discretized_context[c_name] = copy.deepcopy(config_context[c_name])\n",
    "    sim.discretize(discretized_context[c_name], discretization_policy=sim.discretization_policy, coefficients=c_coeff)\n",
    "    discretized_data, _, _ = sim.gen_data(\n",
    "        discretized_context[c_name], sim.n_per_config, \n",
    "        coefficients=c_coeff, add_error=True, data_min=reward_raw_min, data_max=reward_raw_max, plot_2d=True)\n",
    "    config_context[c_name]['configs']['errors'] = sim.ci_dist\n",
    "    \n",
    "    # Save and summarize\n",
    "    config_output[c_name] = sim.update_output_config(config_context[c_name])\n",
    "    df_context = sim.export_data(c, discretized_data, to_file=False)\n",
    "    df_all = df_all.append(df_context)\n",
    "    df_summary = sim.summarize_df(df_summary, c, num_values)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Export Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_summary.to_csv(sim.summary_file_path, index=False)\n",
    "df_all.to_csv(sim.all_data_path, index=False)\n",
    "json.dump(config_output, open(sim.config_path, 'w+'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
